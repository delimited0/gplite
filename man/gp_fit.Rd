% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gp_fit.R, R/gp_mcmc.R
\name{gp_fit}
\alias{gp_fit}
\alias{gp_mcmc}
\title{Fit a GP model}
\usage{
gp_fit(gp, x, y, trials = NULL, jitter = NULL, ...)

gp_mcmc(gp, x, y, trials = NULL, jitter = NULL, ...)
}
\arguments{
\item{gp}{The gp model object to be fitted.}

\item{x}{n-by-d matrix of input values (n is the number of observations and d the input dimension). 
Can also be a vector of length n if the model has only a single input.}

\item{y}{Vector of n output (target) values.}

\item{trials}{Vector of length n giving the number of trials for each observation in binomial 
(and beta binomial) model.}

\item{jitter}{Magnitude of diagonal jitter for covariance matrices for numerical stability.
Default is 1e-6.}

\item{...}{Further arguments to be passed to \link{rstan}'s function 
\code{\link[rstan]{sampling}} if \code{gp_mcmc} was called.}
}
\value{
An updated GP model object.
}
\description{
Function \code{gp_fit} fits a GP model with the current hyperparameters. 
Notice that this function does not optimize the hyperparameters in any way, 
but only finds the analytical posterior approximation (depending on chosen
 \code{\link{approx}}) for the latent values with the current hyperparameters. 
Function \code{gp_mcmc} draws from the posterior of the latent values 
given the current hyperparameter estimates using MCMC. For optimizing the hyperparameter
values, see \code{gp_optim}.
}
\section{References}{


Rasmussen, C. E. and Williams, C. K. I. (2006). Gaussian processes for machine learning.
MIT Press.
}

\examples{
\donttest{

# Generate some toy data
set.seed(32004)
n <- 150
sigma <- 0.1
x <- rnorm(n)
ycont <- sin(3*x)*exp(-abs(x)) +  rnorm(n)*sigma
y <- rep(0,n)
y[ycont > 0] <- 1
trials <- rep(1,n)

# Analytic approximation (Laplace)
cf <- cf_sexp(lscale=0.3, magn=3)
gp <- gp_init(cf, lik_binomial())
gp <- gp_fit(gp, x, y, trials=trials)

# MCMC solution
gpmc <- gp_mcmc(gp, x, y, trials=trials, chains=2, iter=1000)
}

}
